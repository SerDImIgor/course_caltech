{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Data\n",
    "import numpy as np\n",
    "def load_data():\n",
    "    data = np.loadtxt('in.dta')\n",
    "    X, Y = np.split(data,[2], axis=-1)\n",
    "    r,c = X.shape\n",
    "    Y = Y.reshape((1,r))[0]\n",
    "    data = np.loadtxt('out.dta')\n",
    "    X_t, Y_t = np.split(data,[2], axis=-1)\n",
    "    r,c = X_t.shape\n",
    "    Y_t = Y_t.reshape((1,r))[0]\n",
    "    return X, Y, X_t, Y_t\n",
    "\n",
    "def convertData(X,Y):\n",
    "    sz = len(Y)\n",
    "    X = np.concatenate((np.ones((sz,1)),\n",
    "                       X,\n",
    "                       (X[:,0].reshape((sz,1)))**2,\n",
    "                       (X[:,1].reshape((sz,1)))**2,\n",
    "                       (X[:,0] * X[:,1]).reshape((sz,1)),\n",
    "                       np.absolute(X[:,0]-X[:,1]).reshape((sz,1)),\n",
    "                       np.absolute(X[:,0]+X[:,1]).reshape((sz,1))\n",
    "                       ),axis=1)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Linear Regression\n",
    "from math import sqrt\n",
    "from math import exp\n",
    "from math import log\n",
    "from math import pow\n",
    "from scipy.optimize import minimize\n",
    "# Lecture 9 slide 11\n",
    "def gZ(z):\n",
    "    return np.exp(z)/(1 + np.exp(z))\n",
    "\n",
    "def metrics(X,Y,W):\n",
    "    r,c = X.shape\n",
    "    y_pr = gZ(np.dot(X,W))\n",
    "    g = np.where(y_pr > 0.5, 1.0,-1.0)\n",
    "    Error = g - Y\n",
    "    Ein = np.count_nonzero(Error)/r\n",
    "    return Ein\n",
    "\n",
    "# Lecture 9 slide 18\n",
    "def cost(W,X,Y,lambd):\n",
    "    m,c = X.shape\n",
    "    theta = np.zeros(m)\n",
    "    J = 0\n",
    "    for i in range(0,m):\n",
    "        J += log( 1 + exp(-Y[i] * np.dot(X[i,:],W.T)))\n",
    "    return J/m + (lambd/m) * np.dot(W,W.T)\n",
    "\n",
    "# Lecture 9 slide 23\n",
    "def gradient(W,X,Y,lambd):\n",
    "    m,c = X.shape\n",
    "    theta = np.zeros(c)\n",
    "    for i in range(0,m):\n",
    "        theta+=(Y[i] * X[i,:]) / (1 + np.exp(Y[i] * np.dot(X[i,:],W.T)))\n",
    "    theta = (-(1/m) * theta )\n",
    "    return  theta * 0.01\n",
    "\n",
    "def LinerRegression(X, Y,lambd):\n",
    "    X,Y = convertData(X, Y)\n",
    "    r,c = X.shape\n",
    "    W = np.zeros(c)\n",
    "    res = minimize(cost, W,args=(X,Y,lambd), method='BFGS', jac=gradient,options={'disp': False,'maxiter':100000})\n",
    "    print(res.success)\n",
    "    return res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "lambda=0\n",
      "True\n",
      "EIN=0.0\n",
      "EOUT=0.092\n",
      "Response value = b\n",
      "---\n",
      "---\n",
      "lambda=0.001\n",
      "False\n",
      "EIN=0.05714285714285714\n",
      "EOUT=0.136\n",
      "Response value = e\n",
      "---\n",
      "---\n",
      "lambda=1000.0\n",
      "False\n",
      "EIN=0.5714285714285714\n",
      "EOUT=0.528\n",
      "Response value = e\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "def findNearest(arrEIN,arrEOUT,Ein,Eout):\n",
    "    Min = 100\n",
    "    arrayIndex = ['a','b','c','d','e']\n",
    "    minIdx = '-'\n",
    "    for ein,eout,idR in zip(arrEIN,arrEOUT,arrayIndex):\n",
    "        tm = sqrt((ein-Ein)**2 + (eout-Eout)**2)\n",
    "        if tm < Min:\n",
    "            Min = tm\n",
    "            minIdx = idR\n",
    "    print('Response value = ' + minIdx)\n",
    "\n",
    "def printError(X_train, Y_train, X_test, Y_test,W):\n",
    "    X_train,Y_train = convertData(X_train, Y_train)\n",
    "    EIN = metrics(X_train,Y_train,W)\n",
    "    print('EIN='+str(EIN))\n",
    "\n",
    "    X_test,Y_test = convertData(X_test,Y_test)\n",
    "    EOUT = metrics(X_test,Y_test,W)\n",
    "    print('EOUT='+str(EOUT))\n",
    "    return EIN,EOUT\n",
    "\n",
    "def exercise(arrEIN,arrEOUT,k = None):\n",
    "    if k is None:\n",
    "        lambd = 0\n",
    "    else:\n",
    "        lambd = pow(10,k)\n",
    "    print('---')\n",
    "    print('lambda='+str(lambd))\n",
    "    X_train, Y_train, X_test, Y_test = load_data()\n",
    "    W = LinerRegression(X_train, Y_train,lambd)\n",
    "    EIN,EOUT=printError(X_train, Y_train, X_test, Y_test,W)\n",
    "    findNearest(arrEIN,arrEOUT,EIN,EOUT)\n",
    "    print('---')\n",
    "\n",
    "#Ex 2\n",
    "arrEIN = np.array([0.03,0.03,0.04,0.04,0.05])\n",
    "arrEOUT = np.array([0.08,0.1,0.09,0.11,0.1])\n",
    "exercise(arrEIN,arrEOUT)\n",
    "#Ex 3\n",
    "arrEIN = np.array([0.01,0.02,0.02,0.03,0.03])\n",
    "arrEOUT = np.array([0.02,0.04,0.06,0.08,0.1])\n",
    "exercise(arrEIN,arrEOUT,-3)\n",
    "#Ex 4\n",
    "arrEIN = np.array([0.2,0.2,0.3,0.3,0.4])\n",
    "arrEOUT = np.array([0.2,0.3,0.3,0.4,0.4])\n",
    "exercise(arrEIN,arrEOUT,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
